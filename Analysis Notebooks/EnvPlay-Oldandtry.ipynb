{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7a861a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"df = pd.read_csv('../datasets/downew30.csv')\\nindata = data_split(df, '2015-01-01','2015-05-05')\\ntarget_step =len(indata.Date.unique())\\ntarget_step\\ntrain_env = StockEnvTrain(indata, indata,stock_dim=30, config=EnvConfig)\\nagent_builder = DRLAgent(StockEnvTrain, indata, EnvConfig)\\nmodel_kwargs = {\\n    'learning_rate':0.002,\\n    'batch_size':8,\\n    'gamma':0.95,\\n    'seed':42,\\n    'net_dimension':160,\\n    'target_step':160,\\n    'eval_time_gap':10\\n}\\nmodel = agent_builder.get_model('ppo', model_kwargs)\\nagent_builder.train_model(model, './',total_timesteps=100)\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os,sys,inspect\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from datetime import datetime\n",
    "from agents.Base import deepagents, run\n",
    "from agents.BlueAgents import *\n",
    "from data.preprocessing import data_split, get_price, DataProcessor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from agents.wrappers.ObservationWrapper import NormalizedEnv\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from env.EnvStock_train import StockEnvTrain\n",
    "from env.EnvStock_trade import StockEnvTrade\n",
    "from env.EnvStock_val import StockEnvValidation\n",
    "from env.crypto.SingleCryptoEnv import SingleCryptoEnv\n",
    "from stable_baselines3 import A2C, PPO\n",
    "from env.crypto.SingleCryptoEnv import SingleCryptoEnv\n",
    "from env.BaseEnv import EnvConfig\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\"\"\"df = pd.read_csv('../datasets/downew30.csv')\n",
    "indata = data_split(df, '2015-01-01','2015-05-05')\n",
    "target_step =len(indata.Date.unique())\n",
    "target_step\n",
    "train_env = StockEnvTrain(indata, indata,stock_dim=30, config=EnvConfig)\n",
    "agent_builder = DRLAgent(StockEnvTrain, indata, EnvConfig)\n",
    "model_kwargs = {\n",
    "    'learning_rate':0.002,\n",
    "    'batch_size':8,\n",
    "    'gamma':0.95,\n",
    "    'seed':42,\n",
    "    'net_dimension':160,\n",
    "    'target_step':160,\n",
    "    'eval_time_gap':10\n",
    "}\n",
    "model = agent_builder.get_model('ppo', model_kwargs)\n",
    "agent_builder.train_model(model, './',total_timesteps=100)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58e64b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from env.BaseEnv import EnvConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "168879b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/downew30.csv')\n",
    "cwd = '../AgentResult'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "624553b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indata = data_split(df, '2010-01-01','2021-12-25')\n",
    "indtwo = data_split(df, '2015-01-01','2015-01-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab7d8ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = len(indata) // 4\n",
    "N = int(len(indata)/S)\n",
    "frames = [ indata.iloc[i*S:(i+1)*S].copy() for i in range(N+1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e07386a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2990"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_step =len(indata.Date.unique())\n",
    "target_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ad96ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dloader = DataProcessor('crypto',['btc'],'2019-01-01','2022-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7d95a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe = dloader.get_crypto_price('btc_usdt_1d.csv', 'binance', 3, 'BTC/USDT', '1d', '2018-03-0200:00:00Z', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97ad7c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#btc = pd.read_csv('./data/raw/Binance/btc_usdt_1m.csv',names=['Date','open','high','low','close','volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ad06291",
   "metadata": {},
   "outputs": [],
   "source": [
    "indtwo.Date = pd.to_datetime(indtwo.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d408437c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c87d628d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state_trade' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_856/1537647341.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVecNormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDummyVecEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mStockEnvTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstock_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime_window\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEnvConfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m train_envtwo = VecNormalize(DummyVecEnv([lambda: StockEnvTrade(df=indtwo, index_df=indtwo,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                                                \u001b[0munique_trade_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                                \u001b[0minitial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                                \u001b[0mstock_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEnvConfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, env_fns)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_fns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menv_fns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mVecEnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv_fns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_fns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menv_fns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mVecEnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv_fns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_856/1537647341.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                                \u001b[0minitial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                                \u001b[0mstock_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEnvConfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                                                                previous_state=state_trade)]),)\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'state_trade' is not defined"
     ]
    }
   ],
   "source": [
    "train_env = VecNormalize(DummyVecEnv([lambda: StockEnvTrain(indata, indata,stock_dim=30,time_window=15, config=EnvConfig)]))\n",
    "train_envtwo = VecNormalize(DummyVecEnv([lambda: StockEnvTrade(df=indtwo, index_df=indtwo,\n",
    "                                                               unique_trade_date=[datetime.now()],\n",
    "                                                               initial=False,\n",
    "                                                               stock_dim=30, config=EnvConfig, \n",
    "                                                               previous_state=state_trade)]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e07fb7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StockEnvTrain(indata, indata,stock_dim=30, time_window=10, config=EnvConfig)\n",
    "#train_env = NormalizedEnv(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b79c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05515579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1353"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a76e76e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10892/2417795126.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStockEnvTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstock_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEnvConfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNormalizedEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Code\\Finance\\Bot\\FundSimulator\\agents\\wrappers\\ObservationWrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, env, ob, ret, clipob, cliprew, gamma, epsilon)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mNormalizedEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclipob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcliprew\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.99\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNormalizedEnv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mob_rms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRunningMeanStd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mob\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mret_rms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRunningMeanStd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "env = StockEnvTrain(indata, indata,stock_dim=30, config=EnvConfig)\n",
    "train_env = NormalizedEnv(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5560fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = pd.read_csv('results/trade_memory_ppo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98b3e6a",
   "metadata": {},
   "source": [
    "# Own agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be7f4e0",
   "metadata": {},
   "source": [
    "1. Winner params\n",
    "'''\n",
    "model_kwargs = {\n",
    "    'learning_rate':0.0027,\n",
    "    'batch_size':64,\n",
    "    'gamma':0.99,\n",
    "    'seed':42069,\n",
    "    'net_dimension':256, # Change this dimension to be more dynamic\n",
    "    'target_step':5000,\n",
    "    'eval_time_gap':10\n",
    "}\n",
    "model_name = 'jim-ppo-v2'\n",
    "model_type = 'ppo'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3606712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "    'learning_rate':0.0027,\n",
    "    'batch_size':64,\n",
    "    'gamma':0.99,\n",
    "    'seed':42069,\n",
    "    'net_dimension':256, # Change this dimension to be more dynamic\n",
    "    'target_step':90000,\n",
    "    'eval_time_gap':10\n",
    "}\n",
    "model_name = 'jim-ppo-90000'\n",
    "model_type = 'ppo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "630f0fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_builder = DRLAgent(model_name,model_type, StockEnvTrain, \n",
    "                         StockEnvValidation, \n",
    "                         StockEnvTrade, indata, EnvConfig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29d0b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = agent_builder.get_model('ppo', model_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489ca633",
   "metadata": {},
   "source": [
    "- [ ] Change the timesteps version make sure it does reiterate with same agent\n",
    "- [x] Normalize Inputs for the model\n",
    "- [x] Normalize reward function\n",
    "- [ ] Vectorized paralel envs\n",
    "- [x] start trading from 2016\n",
    "- [ ] Add PBT to evaluator\n",
    "- [x] Change neet dimension problem here you cannot make it another than 160 \n",
    "- [ ] Create a database for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b931086d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "======Model training from:  2010-01-01 to  2016-01-04\n",
      "======Training Agents with the population of 1========\n",
      "| Remove cwd: ./trained_models\n",
      "Using device:  cpu\n",
      "################################################################################\n",
      "ID     Step    maxR |    avgR   stdR   avgS  stdS |    expR   objC   etc.\n",
      "0  8.90e+04    7.21 |    7.21    0.0     62     0 |   -0.49   0.79   0.37  -0.50\n",
      "| UsedTime:     783 | SavedDir: ./trained_models | Total Step: 89032\n",
      "======jim-ppo-90000 Validation from:  2016-01-04 to  2016-04-04\n",
      "======Recurrent PPO Validation from:  2016-01-04 to  2016-04-05\n",
      "Total reward at validation for Reccurent PPO 0\n",
      "================================================================================\n",
      "Best params,  {'learning_rate': 0.002, 'batch_size': 8, 'gamma': 0.95, 'seed': 42, 'net_dimension': 160, 'target_step': 160, 'eval_time_gap': 10}\n",
      "================================================================================\n",
      "======Trading from:  2016-04-05 to  2016-07-05\n",
      "Using device:  cpu\n",
      "previous_total_asset:1000000\n",
      "end_total_asset:1020342.9017355616\n",
      "total_asset_change:20342.90173556155\n",
      "Total cash is: 0.5668547327392837$ and total holdings in stocks are 1020342.3348808289$\n",
      "Buy & Hold strategy with previous total asset:  1027898.381899113\n",
      "Total Cost:  999.0004327125549\n",
      "Sum of rewards  -239766.28900680516\n",
      "Total trades:  156\n",
      "Total buy orders are 156 and total sell orders are 0\n",
      "Total days in turbulance:  0\n",
      "Sharpe:  0.08914286237368321\n",
      "Test Finished!\n",
      "episode_return % 0.020299999999999985\n",
      "============================================\n",
      "======Model training from:  2010-01-01 to  2016-04-05\n",
      "======Training Agents with the population of 1========\n",
      "| Remove cwd: ./trained_models\n",
      "Using device:  cpu\n",
      "################################################################################\n",
      "ID     Step    maxR |    avgR   stdR   avgS  stdS |    expR   objC   etc.\n",
      "0  8.96e+04   -6.58 |   -6.58    0.0     62     0 |   -0.55   0.75   0.29  -0.50\n",
      "| UsedTime:     858 | SavedDir: ./trained_models | Total Step: 89605\n",
      "======jim-ppo-90000 Validation from:  2016-04-05 to  2016-07-01\n",
      "======Recurrent PPO Validation from:  2016-04-05 to  2016-07-05\n",
      "Total reward at validation for Reccurent PPO 0\n",
      "================================================================================\n",
      "Best params,  {'learning_rate': 0.002, 'batch_size': 8, 'gamma': 0.95, 'seed': 42, 'net_dimension': 160, 'target_step': 160, 'eval_time_gap': 10}\n",
      "================================================================================\n",
      "======Trading from:  2016-07-05 to  2016-10-03\n",
      "Using device:  cpu\n",
      "Saving to  results/account_value_trade_main_jim-ppo-90000.csv\n",
      "previous_total_asset:1020342.9017355616\n",
      "end_total_asset:1046904.6937827438\n",
      "total_asset_change:26561.792047182214\n",
      "Total cash is: 12.141359266545631$ and total holdings in stocks are 1046892.5524234772$\n",
      "Buy & Hold strategy with previous total asset:  1059120.5633685098\n",
      "Total Cost:  1227.4061797466275\n",
      "Sum of rewards  -197643.11131121975\n",
      "Total trades:  173\n",
      "Total buy orders are 91 and total sell orders are 82\n",
      "Total days in turbulance:  0\n",
      "Sharpe:  0.13630371299777191\n",
      "Test Finished!\n",
      "episode_return % 0.04689999999999994\n",
      "============================================\n",
      "======Model training from:  2010-01-01 to  2016-07-05\n",
      "======Training Agents with the population of 1========\n",
      "| Remove cwd: ./trained_models\n",
      "Using device:  cpu\n",
      "################################################################################\n",
      "ID     Step    maxR |    avgR   stdR   avgS  stdS |    expR   objC   etc.\n",
      "0  8.99e+04   -6.68 |   -6.68    0.0     62     0 |   -0.61   0.69   0.23  -0.50\n",
      "| UsedTime:     857 | SavedDir: ./trained_models | Total Step: 89926\n",
      "======jim-ppo-90000 Validation from:  2016-07-05 to  2016-09-30\n",
      "======Recurrent PPO Validation from:  2016-07-05 to  2016-10-03\n",
      "Total reward at validation for Reccurent PPO 0\n",
      "================================================================================\n",
      "Best params,  {'learning_rate': 0.002, 'batch_size': 8, 'gamma': 0.95, 'seed': 42, 'net_dimension': 160, 'target_step': 160, 'eval_time_gap': 10}\n",
      "================================================================================\n",
      "======Trading from:  2016-10-03 to  2017-01-03\n",
      "Using device:  cpu\n",
      "Saving to  results/account_value_trade_main_jim-ppo-90000.csv\n",
      "previous_total_asset:1046904.6937827438\n",
      "end_total_asset:1131945.9698118232\n",
      "total_asset_change:85041.27602907945\n",
      "Total cash is: 15.862031366639314$ and total holdings in stocks are 1131930.1077804565$\n",
      "Buy & Hold strategy with previous total asset:  1118241.127212829\n",
      "Total Cost:  1171.1924519844056\n",
      "Sum of rewards  637674.051286951\n",
      "Total trades:  182\n",
      "Total buy orders are 103 and total sell orders are 79\n",
      "Total days in turbulance:  0\n",
      "Sharpe:  0.399226067020633\n",
      "Test Finished!\n",
      "episode_return % 0.1318999999999999\n",
      "============================================\n",
      "======Model training from:  2010-01-01 to  2016-10-03\n",
      "======Training Agents with the population of 1========\n",
      "| Remove cwd: ./trained_models\n",
      "Using device:  cpu\n",
      "################################################################################\n",
      "ID     Step    maxR |    avgR   stdR   avgS  stdS |    expR   objC   etc.\n",
      "0  9.00e+04   -0.10 |   -0.10    0.0     62     0 |   -0.66   0.72   0.23  -0.50\n",
      "| UsedTime:     773 | SavedDir: ./trained_models | Total Step: 89995\n",
      "======jim-ppo-90000 Validation from:  2016-10-03 to  2016-12-30\n",
      "======Recurrent PPO Validation from:  2016-10-03 to  2017-01-03\n",
      "Total reward at validation for Reccurent PPO 0\n",
      "================================================================================\n",
      "Best params,  {'learning_rate': 0.002, 'batch_size': 8, 'gamma': 0.95, 'seed': 42, 'net_dimension': 160, 'target_step': 160, 'eval_time_gap': 10}\n",
      "================================================================================\n",
      "======Trading from:  2017-01-03 to  2017-04-04\n",
      "Using device:  cpu\n",
      "Saving to  results/account_value_trade_main_jim-ppo-90000.csv\n",
      "previous_total_asset:1131945.9698118232\n",
      "end_total_asset:1214691.0443668617\n",
      "total_asset_change:82745.07455503847\n",
      "Total cash is: 9.71940424569766$ and total holdings in stocks are 1214681.324962616$\n",
      "Buy & Hold strategy with previous total asset:  1183323.3164487386\n",
      "Total Cost:  754.9610399017333\n",
      "Sum of rewards  1214269.000479351\n",
      "Total trades:  164\n",
      "Total buy orders are 88 and total sell orders are 76\n",
      "Total days in turbulance:  0\n",
      "Sharpe:  0.4029609534952647\n",
      "Test Finished!\n",
      "episode_return % 0.2146999999999999\n",
      "============================================\n",
      "======Model training from:  2010-01-01 to  2017-01-03\n",
      "======Training Agents with the population of 1========\n",
      "| Remove cwd: ./trained_models\n",
      "Using device:  cpu\n",
      "################################################################################\n",
      "ID     Step    maxR |    avgR   stdR   avgS  stdS |    expR   objC   etc.\n",
      "0  8.98e+04   -1.94 |   -1.94    0.0     62     0 |   -0.71   0.76   0.31  -0.50\n",
      "| UsedTime:     755 | SavedDir: ./trained_models | Total Step: 89812\n",
      "======jim-ppo-90000 Validation from:  2017-01-03 to  2017-04-03\n",
      "======Recurrent PPO Validation from:  2017-01-03 to  2017-04-04\n",
      "Total reward at validation for Reccurent PPO 0\n",
      "================================================================================\n",
      "Best params,  {'learning_rate': 0.002, 'batch_size': 8, 'gamma': 0.95, 'seed': 42, 'net_dimension': 160, 'target_step': 160, 'eval_time_gap': 10}\n",
      "================================================================================\n",
      "======Trading from:  2017-04-04 to  2017-07-05\n",
      "Using device:  cpu\n",
      "Saving to  results/account_value_trade_main_jim-ppo-90000.csv\n",
      "previous_total_asset:1214691.0443668617\n",
      "end_total_asset:1251354.225988646\n",
      "total_asset_change:36663.181621784344\n",
      "Total cash is: 20.125486631767764$ and total holdings in stocks are 1251334.1005020142$\n",
      "Buy & Hold strategy with previous total asset:  1255397.9973629906\n",
      "Total Cost:  938.9135320243839\n",
      "Sum of rewards  -86720.72757023759\n",
      "Total trades:  141\n",
      "Total buy orders are 98 and total sell orders are 43\n",
      "Total days in turbulance:  0\n",
      "Sharpe:  0.2129711166730217\n",
      "Test Finished!\n",
      "episode_return % 0.25140000000000007\n",
      "============================================\n",
      "======Model training from:  2010-01-01 to  2017-04-04\n",
      "======Training Agents with the population of 1========\n",
      "| Remove cwd: ./trained_models\n",
      "Using device:  cpu\n",
      "################################################################################\n",
      "ID     Step    maxR |    avgR   stdR   avgS  stdS |    expR   objC   etc.\n"
     ]
    }
   ],
   "source": [
    "agent_builder.run_prediction(model_kwargs, total_timesteps=1000)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e515ba3a",
   "metadata": {},
   "source": [
    "2 ** 9 * 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "015c02c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200 / 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8edf2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(0.43,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f413a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
