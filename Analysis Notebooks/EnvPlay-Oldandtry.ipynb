{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a861a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df = pd.read_csv('../datasets/downew30.csv')\\nindata = data_split(df, '2015-01-01','2015-05-05')\\ntarget_step =len(indata.Date.unique())\\ntarget_step\\ntrain_env = StockEnvTrain(indata, indata,stock_dim=30, config=EnvConfig)\\nagent_builder = DRLAgent(StockEnvTrain, indata, EnvConfig)\\nmodel_kwargs = {\\n    'learning_rate':0.002,\\n    'batch_size':8,\\n    'gamma':0.95,\\n    'seed':42,\\n    'net_dimension':160,\\n    'target_step':160,\\n    'eval_time_gap':10\\n}\\nmodel = agent_builder.get_model('ppo', model_kwargs)\\nagent_builder.train_model(model, './',total_timesteps=100)\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os,sys,inspect\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from datetime import datetime\n",
    "from agents.Base import deepagents, run\n",
    "from agents.BlueAgents import *\n",
    "from data.preprocessing import data_split, get_price, DataProcessor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from agents.wrappers.ObservationWrapper import NormalizedEnv\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from env.EnvStock_train import StockEnvTrain\n",
    "from env.EnvStock_trade import StockEnvTrade\n",
    "from env.EnvStock_val import StockEnvValidation\n",
    "from env.crypto.SingleCryptoEnv import SingleCryptoEnv\n",
    "from stable_baselines3 import A2C, PPO\n",
    "from env.crypto.SingleCryptoEnv import SingleCryptoEnv\n",
    "from env.BaseEnv import EnvConfig\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\"\"\"df = pd.read_csv('../datasets/downew30.csv')\n",
    "indata = data_split(df, '2015-01-01','2015-05-05')\n",
    "target_step =len(indata.Date.unique())\n",
    "target_step\n",
    "train_env = StockEnvTrain(indata, indata,stock_dim=30, config=EnvConfig)\n",
    "agent_builder = DRLAgent(StockEnvTrain, indata, EnvConfig)\n",
    "model_kwargs = {\n",
    "    'learning_rate':0.002,\n",
    "    'batch_size':8,\n",
    "    'gamma':0.95,\n",
    "    'seed':42,\n",
    "    'net_dimension':160,\n",
    "    'target_step':160,\n",
    "    'eval_time_gap':10\n",
    "}\n",
    "model = agent_builder.get_model('ppo', model_kwargs)\n",
    "agent_builder.train_model(model, './',total_timesteps=100)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58e64b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from env.BaseEnv import EnvConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "168879b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/downew30.csv')\n",
    "cwd = '../AgentResult'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "624553b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indata = data_split(df, '2010-01-01','2021-12-25')\n",
    "indtwo = data_split(df, '2015-01-01','2015-01-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7d8ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = len(indata) // 4\n",
    "N = int(len(indata)/S)\n",
    "frames = [ indata.iloc[i*S:(i+1)*S].copy() for i in range(N+1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e07386a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2990"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_step =len(indata.Date.unique())\n",
    "target_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ad96ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dloader = DataProcessor('crypto',['btc'],'2019-01-01','2022-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7d95a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe = dloader.get_crypto_price('btc_usdt_1d.csv', 'binance', 3, 'BTC/USDT', '1d', '2018-03-0200:00:00Z', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97ad7c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#btc = pd.read_csv('./data/raw/Binance/btc_usdt_1m.csv',names=['Date','open','high','low','close','volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ad06291",
   "metadata": {},
   "outputs": [],
   "source": [
    "indtwo.Date = pd.to_datetime(indtwo.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d408437c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87d628d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state_trade' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22524/1537647341.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVecNormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDummyVecEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mStockEnvTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstock_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime_window\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEnvConfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m train_envtwo = VecNormalize(DummyVecEnv([lambda: StockEnvTrade(df=indtwo, index_df=indtwo,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                                                \u001b[0munique_trade_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                                \u001b[0minitial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                                \u001b[0mstock_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEnvConfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, env_fns)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_fns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menv_fns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mVecEnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv_fns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_fns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menv_fns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mVecEnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv_fns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22524/1537647341.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                                \u001b[0minitial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                                \u001b[0mstock_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEnvConfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                                                                previous_state=state_trade)]),)\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'state_trade' is not defined"
     ]
    }
   ],
   "source": [
    "train_env = VecNormalize(DummyVecEnv([lambda: StockEnvTrain(indata, indata,stock_dim=30,time_window=15, config=EnvConfig)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e07fb7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "conf = EnvConfig(quantity_buying=False, HMAX_NORMALIZE=1000)\n",
    "print(conf.quantity_buying)\n",
    "env = StockEnvTrain(indata, indata,stock_dim=30, time_window=10, config=conf)\n",
    "#train_env = NormalizedEnv(env)\n",
    "actions = np.random.rand(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b79c08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88230458, 0.25541748, 0.4563505 , 0.44762209, 0.23167624,\n",
       "       0.27391022, 0.23528   , 0.44265522, 0.88723818, 0.21661075,\n",
       "       0.81519106, 0.96897939, 0.31416518, 0.27861097, 0.81377838,\n",
       "       0.50398968, 0.26268956, 0.60751329, 0.54204423, 0.00288137,\n",
       "       0.69428868, 0.25508031, 0.49623654, 0.7996958 , 0.57957944,\n",
       "       0.0058184 , 0.70224188, 0.74382735, 0.99083318, 0.01159962])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = env.reset()\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05515579",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, rew, done , info = env.step(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a76e76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[985760.3466679667,\n",
       " 6.48321008682251,\n",
       " 36.11091613769531,\n",
       " 46.91008758544922,\n",
       " 43.49469757080078,\n",
       " 17.878368377685547,\n",
       " 48.96447372436523,\n",
       " 31.110923767089844,\n",
       " 27.167415618896484,\n",
       " 140.90147399902344,\n",
       " 21.736352920532227,\n",
       " 83.92987060546875,\n",
       " 14.716354370117188,\n",
       " 46.07190322875977,\n",
       " 32.120052337646484,\n",
       " 19.26396942138672,\n",
       " 44.85563659667969,\n",
       " 61.616111755371094,\n",
       " 26.08905029296875,\n",
       " 23.670154571533203,\n",
       " 13.911550521850586,\n",
       " 12.102463722229006,\n",
       " 42.304443359375,\n",
       " 33.944351196289055,\n",
       " 36.64289093017578,\n",
       " 28.93057060241699,\n",
       " 20.08134651184082,\n",
       " 16.616043090820312,\n",
       " 27.28571510314941,\n",
       " 40.84796142578125,\n",
       " 42.95717239379883,\n",
       " 133.0,\n",
       " 7.0,\n",
       " 9.0,\n",
       " 10.0,\n",
       " 12.0,\n",
       " 5.0,\n",
       " 7.0,\n",
       " 16.0,\n",
       " 6.0,\n",
       " 9.0,\n",
       " 9.0,\n",
       " 65.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 41.0,\n",
       " 11.0,\n",
       " 4.0,\n",
       " 23.0,\n",
       " 22.0,\n",
       " 0.0,\n",
       " 57.0,\n",
       " 5.0,\n",
       " 14.0,\n",
       " 21.0,\n",
       " 19.0,\n",
       " 0.0,\n",
       " 41.0,\n",
       " 27.0,\n",
       " 24.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[0:61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5560fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = pd.read_csv('results/trade_memory_ppo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98b3e6a",
   "metadata": {},
   "source": [
    "# Own agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be7f4e0",
   "metadata": {},
   "source": [
    "1. Winner params\n",
    "'''\n",
    "model_kwargs = {\n",
    "    'learning_rate':0.0027,\n",
    "    'batch_size':64,\n",
    "    'gamma':0.99,\n",
    "    'seed':42069,\n",
    "    'net_dimension':256, # Change this dimension to be more dynamic\n",
    "    'target_step':5000,\n",
    "    'eval_time_gap':10\n",
    "}\n",
    "model_name = 'jim-ppo-v2'\n",
    "model_type = 'ppo'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3606712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "    'learning_rate':0.0027,\n",
    "    'batch_size':64,\n",
    "    'gamma':0.99,\n",
    "    'seed':42069,\n",
    "    'net_dimension':256, # Change this dimension to be more dynamic\n",
    "    'target_step':90000,\n",
    "    'eval_time_gap':10\n",
    "}\n",
    "model_name = 'jim-ppo-90000'\n",
    "model_type = 'ppo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "630f0fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_builder = DRLAgent(model_name,model_type, StockEnvTrain, \n",
    "                         StockEnvValidation, \n",
    "                         StockEnvTrade, indata, EnvConfig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29d0b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = agent_builder.get_model('ppo', model_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489ca633",
   "metadata": {},
   "source": [
    "- [ ] Change the timesteps version make sure it does reiterate with same agent\n",
    "- [x] Normalize Inputs for the model\n",
    "- [x] Normalize reward function\n",
    "- [ ] Vectorized paralel envs\n",
    "- [x] start trading from 2016\n",
    "- [ ] Add PBT to evaluator\n",
    "- [x] Change neet dimension problem here you cannot make it another than 160 \n",
    "- [ ] Create a database for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b931086d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "======Model training from:  2010-01-01 to  2016-01-04\n",
      "======Training Agents with the population of 1========\n",
      "| Remove cwd: ./trained_models\n",
      "Using device:  cpu\n",
      "################################################################################\n",
      "ID     Step    maxR |    avgR   stdR   avgS  stdS |    expR   objC   etc.\n",
      "0  8.90e+04    7.21 |    7.21    0.0     62     0 |   -0.49   0.79   0.37  -0.50\n",
      "| UsedTime:     783 | SavedDir: ./trained_models | Total Step: 89032\n",
      "======jim-ppo-90000 Validation from:  2016-01-04 to  2016-04-04\n",
      "======Recurrent PPO Validation from:  2016-01-04 to  2016-04-05\n",
      "Total reward at validation for Reccurent PPO 0\n",
      "================================================================================\n",
      "Best params,  {'learning_rate': 0.002, 'batch_size': 8, 'gamma': 0.95, 'seed': 42, 'net_dimension': 160, 'target_step': 160, 'eval_time_gap': 10}\n",
      "================================================================================\n",
      "======Trading from:  2016-04-05 to  2016-07-05\n",
      "Using device:  cpu\n",
      "previous_total_asset:1000000\n",
      "end_total_asset:1020342.9017355616\n",
      "total_asset_change:20342.90173556155\n",
      "Total cash is: 0.5668547327392837$ and total holdings in stocks are 1020342.3348808289$\n",
      "Buy & Hold strategy with previous total asset:  1027898.381899113\n",
      "Total Cost:  999.0004327125549\n",
      "Sum of rewards  -239766.28900680516\n",
      "Total trades:  156\n",
      "Total buy orders are 156 and total sell orders are 0\n",
      "Total days in turbulance:  0\n",
      "Sharpe:  0.08914286237368321\n",
      "Test Finished!\n",
      "episode_return % 0.020299999999999985\n",
      "============================================\n",
      "======Model training from:  2010-01-01 to  2016-04-05\n",
      "======Training Agents with the population of 1========\n",
      "| Remove cwd: ./trained_models\n",
      "Using device:  cpu\n",
      "################################################################################\n",
      "ID     Step    maxR |    avgR   stdR   avgS  stdS |    expR   objC   etc.\n",
      "0  8.96e+04   -6.58 |   -6.58    0.0     62     0 |   -0.55   0.75   0.29  -0.50\n",
      "| UsedTime:     858 | SavedDir: ./trained_models | Total Step: 89605\n",
      "======jim-ppo-90000 Validation from:  2016-04-05 to  2016-07-01\n",
      "======Recurrent PPO Validation from:  2016-04-05 to  2016-07-05\n",
      "Total reward at validation for Reccurent PPO 0\n",
      "================================================================================\n",
      "Best params,  {'learning_rate': 0.002, 'batch_size': 8, 'gamma': 0.95, 'seed': 42, 'net_dimension': 160, 'target_step': 160, 'eval_time_gap': 10}\n",
      "================================================================================\n",
      "======Trading from:  2016-07-05 to  2016-10-03\n",
      "Using device:  cpu\n",
      "Saving to  results/account_value_trade_main_jim-ppo-90000.csv\n",
      "previous_total_asset:1020342.9017355616\n",
      "end_total_asset:1046904.6937827438\n",
      "total_asset_change:26561.792047182214\n",
      "Total cash is: 12.141359266545631$ and total holdings in stocks are 1046892.5524234772$\n",
      "Buy & Hold strategy with previous total asset:  1059120.5633685098\n",
      "Total Cost:  1227.4061797466275\n",
      "Sum of rewards  -197643.11131121975\n",
      "Total trades:  173\n",
      "Total buy orders are 91 and total sell orders are 82\n",
      "Total days in turbulance:  0\n",
      "Sharpe:  0.13630371299777191\n",
      "Test Finished!\n",
      "episode_return % 0.04689999999999994\n",
      "============================================\n",
      "======Model training from:  2010-01-01 to  2016-07-05\n",
      "======Training Agents with the population of 1========\n",
      "| Remove cwd: ./trained_models\n",
      "Using device:  cpu\n",
      "################################################################################\n",
      "ID     Step    maxR |    avgR   stdR   avgS  stdS |    expR   objC   etc.\n",
      "0  8.99e+04   -6.68 |   -6.68    0.0     62     0 |   -0.61   0.69   0.23  -0.50\n",
      "| UsedTime:     857 | SavedDir: ./trained_models | Total Step: 89926\n",
      "======jim-ppo-90000 Validation from:  2016-07-05 to  2016-09-30\n",
      "======Recurrent PPO Validation from:  2016-07-05 to  2016-10-03\n",
      "Total reward at validation for Reccurent PPO 0\n",
      "================================================================================\n",
      "Best params,  {'learning_rate': 0.002, 'batch_size': 8, 'gamma': 0.95, 'seed': 42, 'net_dimension': 160, 'target_step': 160, 'eval_time_gap': 10}\n",
      "================================================================================\n",
      "======Trading from:  2016-10-03 to  2017-01-03\n",
      "Using device:  cpu\n",
      "Saving to  results/account_value_trade_main_jim-ppo-90000.csv\n",
      "previous_total_asset:1046904.6937827438\n",
      "end_total_asset:1131945.9698118232\n",
      "total_asset_change:85041.27602907945\n",
      "Total cash is: 15.862031366639314$ and total holdings in stocks are 1131930.1077804565$\n",
      "Buy & Hold strategy with previous total asset:  1118241.127212829\n",
      "Total Cost:  1171.1924519844056\n",
      "Sum of rewards  637674.051286951\n",
      "Total trades:  182\n",
      "Total buy orders are 103 and total sell orders are 79\n",
      "Total days in turbulance:  0\n",
      "Sharpe:  0.399226067020633\n",
      "Test Finished!\n",
      "episode_return % 0.1318999999999999\n",
      "============================================\n",
      "======Model training from:  2010-01-01 to  2016-10-03\n",
      "======Training Agents with the population of 1========\n",
      "| Remove cwd: ./trained_models\n",
      "Using device:  cpu\n",
      "################################################################################\n",
      "ID     Step    maxR |    avgR   stdR   avgS  stdS |    expR   objC   etc.\n",
      "0  9.00e+04   -0.10 |   -0.10    0.0     62     0 |   -0.66   0.72   0.23  -0.50\n",
      "| UsedTime:     773 | SavedDir: ./trained_models | Total Step: 89995\n",
      "======jim-ppo-90000 Validation from:  2016-10-03 to  2016-12-30\n",
      "======Recurrent PPO Validation from:  2016-10-03 to  2017-01-03\n",
      "Total reward at validation for Reccurent PPO 0\n",
      "================================================================================\n",
      "Best params,  {'learning_rate': 0.002, 'batch_size': 8, 'gamma': 0.95, 'seed': 42, 'net_dimension': 160, 'target_step': 160, 'eval_time_gap': 10}\n",
      "================================================================================\n",
      "======Trading from:  2017-01-03 to  2017-04-04\n",
      "Using device:  cpu\n",
      "Saving to  results/account_value_trade_main_jim-ppo-90000.csv\n",
      "previous_total_asset:1131945.9698118232\n",
      "end_total_asset:1214691.0443668617\n",
      "total_asset_change:82745.07455503847\n",
      "Total cash is: 9.71940424569766$ and total holdings in stocks are 1214681.324962616$\n",
      "Buy & Hold strategy with previous total asset:  1183323.3164487386\n",
      "Total Cost:  754.9610399017333\n",
      "Sum of rewards  1214269.000479351\n",
      "Total trades:  164\n",
      "Total buy orders are 88 and total sell orders are 76\n",
      "Total days in turbulance:  0\n",
      "Sharpe:  0.4029609534952647\n",
      "Test Finished!\n",
      "episode_return % 0.2146999999999999\n",
      "============================================\n",
      "======Model training from:  2010-01-01 to  2017-01-03\n",
      "======Training Agents with the population of 1========\n",
      "| Remove cwd: ./trained_models\n",
      "Using device:  cpu\n",
      "################################################################################\n",
      "ID     Step    maxR |    avgR   stdR   avgS  stdS |    expR   objC   etc.\n",
      "0  8.98e+04   -1.94 |   -1.94    0.0     62     0 |   -0.71   0.76   0.31  -0.50\n",
      "| UsedTime:     755 | SavedDir: ./trained_models | Total Step: 89812\n",
      "======jim-ppo-90000 Validation from:  2017-01-03 to  2017-04-03\n",
      "======Recurrent PPO Validation from:  2017-01-03 to  2017-04-04\n",
      "Total reward at validation for Reccurent PPO 0\n",
      "================================================================================\n",
      "Best params,  {'learning_rate': 0.002, 'batch_size': 8, 'gamma': 0.95, 'seed': 42, 'net_dimension': 160, 'target_step': 160, 'eval_time_gap': 10}\n",
      "================================================================================\n",
      "======Trading from:  2017-04-04 to  2017-07-05\n",
      "Using device:  cpu\n",
      "Saving to  results/account_value_trade_main_jim-ppo-90000.csv\n",
      "previous_total_asset:1214691.0443668617\n",
      "end_total_asset:1251354.225988646\n",
      "total_asset_change:36663.181621784344\n",
      "Total cash is: 20.125486631767764$ and total holdings in stocks are 1251334.1005020142$\n",
      "Buy & Hold strategy with previous total asset:  1255397.9973629906\n",
      "Total Cost:  938.9135320243839\n",
      "Sum of rewards  -86720.72757023759\n",
      "Total trades:  141\n",
      "Total buy orders are 98 and total sell orders are 43\n",
      "Total days in turbulance:  0\n",
      "Sharpe:  0.2129711166730217\n",
      "Test Finished!\n",
      "episode_return % 0.25140000000000007\n",
      "============================================\n",
      "======Model training from:  2010-01-01 to  2017-04-04\n",
      "======Training Agents with the population of 1========\n",
      "| Remove cwd: ./trained_models\n",
      "Using device:  cpu\n",
      "################################################################################\n",
      "ID     Step    maxR |    avgR   stdR   avgS  stdS |    expR   objC   etc.\n"
     ]
    }
   ],
   "source": [
    "agent_builder.run_prediction(model_kwargs, total_timesteps=1000)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e515ba3a",
   "metadata": {},
   "source": [
    "2 ** 9 * 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "015c02c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200 / 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8edf2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(0.43,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f413a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
